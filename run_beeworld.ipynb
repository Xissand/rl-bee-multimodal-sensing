{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KN8P97LyIa8-"
      },
      "source": [
        "# Run Bee World Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFq2bfy8fpqR",
        "outputId": "4c08ee6c-2c22-4143-bb8e-2d9f53937eab"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llHNv0OsIcGL",
        "outputId": "2fc68cd1-a7bc-4021-c485-e44b7a23c4cf"
      },
      "outputs": [],
      "source": [
        "# !pip install gymnasium\n",
        "# !pip install stable_baselines3\n",
        "\n",
        "# !git clone https://github.com/alTeska/rl-bee-multimodal-sensing.git\n",
        "# !mv rl-bee-multimodal-sensing/bee.py ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aCnyYH55Ia9F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import gymnasium as gym\n",
        "from bee import BeeWorld\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rCU50LG7Ia9J"
      },
      "outputs": [],
      "source": [
        "def display_video(frames, framerate=30):\n",
        "  \"\"\"Generates video from `frames`.\n",
        "\n",
        "  Args:\n",
        "    frames (ndarray): Array of shape (n_frames, height, width, 3).\n",
        "    framerate (int): Frame rate in units of Hz.\n",
        "\n",
        "  Returns:\n",
        "    Display object.\n",
        "  \"\"\"\n",
        "  height, width, _ = frames[0].shape\n",
        "  dpi = 70\n",
        "  orig_backend = matplotlib.get_backend()\n",
        "  matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
        "  matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
        "  ax.set_axis_off()\n",
        "  ax.set_aspect('equal')\n",
        "  ax.set_position([0, 0, 1, 1])\n",
        "  im = ax.imshow(frames[0])\n",
        "\n",
        "  def update(frame):\n",
        "    im.set_data(frame)\n",
        "    return [im]\n",
        "  interval = 1000/framerate\n",
        "  anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
        "                                  interval=interval, blit=True, repeat=False)\n",
        "  return HTML(anim.to_html5_video())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2SEbhdmlIa9M"
      },
      "source": [
        "## Initialize Gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71zAVtGMIa9N",
        "outputId": "04cefdf2-1f94-4478-e365-5b0c2b6a5815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'vision': 0,\n",
              "  'smell': array([0.0713274], dtype=float32),\n",
              "  'velocity': array([0., 0.], dtype=float32),\n",
              "  'time': array([0.001], dtype=float32)},\n",
              " {'is_success': False})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gym.register(\n",
        "    id=\"BeeWorld\",\n",
        "    entry_point=BeeWorld,\n",
        "    max_episode_steps=3000,\n",
        ")\n",
        "\n",
        "env = gym.make(\"BeeWorld\", render_mode=\"rgb_array\")\n",
        "env.reset()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BGV8hT1gIa9R"
      },
      "source": [
        "## Initialize the RL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ydYM6mdEKwJD"
      },
      "outputs": [],
      "source": [
        "models_dir = \"drive/MyDrive/neuromatch/models/{}\"\n",
        "model_alg = 'TD3'\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir.format(model_alg), exist_ok=True)\n",
        "\n",
        "logdir =\"drive/MyDrive/logs\"\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(logdir, exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to test_logs\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "env = Monitor(env, logdir, allow_early_resets=True)\n",
        "\n",
        "logger = configure(\"test_logs\",[\"stdout\", \"csv\", \"log\", \"tensorboard\", \"json\"])\n",
        "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
        "\n",
        "eval_callback = EvalCallback(env,\n",
        "                             callback_after_eval=stop_train_callback,\n",
        "                             best_model_save_path=models_dir.format(model_alg),\n",
        "                             log_path=logdir,\n",
        "                             eval_freq=1000,\n",
        "                             n_eval_episodes=10,\n",
        "                             deterministic=True,\n",
        "                             render=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "amu9K9iQIa9S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 218      |\n",
            "|    ep_rew_mean     | 943      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 459      |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 872      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.8    |\n",
            "|    critic_loss     | 184      |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 671      |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1000, episode_reward=878.55 +/- 80.45\n",
            "Episode length: 186.40 +/- 122.16\n",
            "Success rate: 100.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 186      |\n",
            "|    mean_reward     | 879      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -50.1    |\n",
            "|    critic_loss     | 6.47e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 872      |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 201      |\n",
            "|    ep_rew_mean     | 916      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 359      |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 1735     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -189     |\n",
            "|    critic_loss     | 6.17e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 1582     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2000, episode_reward=618.55 +/- 843.00\n",
            "Episode length: 439.20 +/- 859.34\n",
            "Success rate: 90.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 439      |\n",
            "|    mean_reward     | 619      |\n",
            "|    success_rate    | 0.9      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -142     |\n",
            "|    critic_loss     | 6.01e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 1735     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 152      |\n",
            "|    ep_rew_mean     | 934      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 301      |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 2215     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -85      |\n",
            "|    critic_loss     | 5.43e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 2206     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 934      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 306      |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 2655     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -47      |\n",
            "|    critic_loss     | 4.24e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 2654     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=3000, episode_reward=884.49 +/- 58.22\n",
            "Episode length: 177.40 +/- 87.24\n",
            "Success rate: 100.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 177      |\n",
            "|    mean_reward     | 884      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 3000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.8    |\n",
            "|    critic_loss     | 3.66e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 2899     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 161      |\n",
            "|    ep_rew_mean     | 918      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 314      |\n",
            "|    time_elapsed    | 11       |\n",
            "|    total_timesteps | 3716     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.4    |\n",
            "|    critic_loss     | 1.79e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 3609     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=4000, episode_reward=916.08 +/- 59.11\n",
            "Episode length: 128.90 +/- 90.41\n",
            "Success rate: 100.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 129      |\n",
            "|    mean_reward     | 916      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 4000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.4    |\n",
            "|    critic_loss     | 1.18e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 3944     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 168      |\n",
            "|    ep_rew_mean     | 911      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 327      |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 4591     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.6    |\n",
            "|    critic_loss     | 1.27e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 4298     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=5000, episode_reward=638.49 +/- 850.88\n",
            "Episode length: 408.10 +/- 873.16\n",
            "Success rate: 90.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 408      |\n",
            "|    mean_reward     | 638      |\n",
            "|    success_rate    | 0.9      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 5000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.4    |\n",
            "|    critic_loss     | 1.55e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 4968     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 158      |\n",
            "|    ep_rew_mean     | 915      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 300      |\n",
            "|    time_elapsed    | 16       |\n",
            "|    total_timesteps | 5001     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=6000, episode_reward=891.00 +/- 53.77\n",
            "Episode length: 168.80 +/- 82.08\n",
            "Success rate: 100.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 169      |\n",
            "|    mean_reward     | 891      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19      |\n",
            "|    critic_loss     | 1.66e+03 |\n",
            "|    learning_rate   | 0.01     |\n",
            "|    n_updates       | 5782     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=7000, episode_reward=639.38 +/- 879.77\n",
            "Episode length: 395.30 +/- 875.58\n",
            "Success rate: 90.00%\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 395      |\n",
            "|    mean_reward     | 639      |\n",
            "|    success_rate    | 0.9      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 7000     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 163      |\n",
            "|    ep_rew_mean     | 911      |\n",
            "|    success_rate    | 1        |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 345      |\n",
            "|    time_elapsed    | 20       |\n",
            "|    total_timesteps | 7015     |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(\n",
        "    mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions)\n",
        ")\n",
        "\n",
        "\n",
        "model = TD3(\n",
        "    \"MultiInputPolicy\",\n",
        "    env,\n",
        "    action_noise=action_noise,\n",
        "    verbose=1,\n",
        "    policy_kwargs = {\n",
        "        \"net_arch\": [200, 200],  # Specify the number of hidden units per layer\n",
        "        \"activation_fn\": nn.ReLU,  # Specify the activation function\n",
        "    }   ,\n",
        "    learning_rate=0.01\n",
        ")\n",
        "model.set_logger(logger)\n",
        "\n",
        "vec_env = model.get_env()\n",
        "obs = vec_env.reset()\n",
        "\n",
        "timesteps = 10000\n",
        "iters = 0\n",
        "while iters < 10:\n",
        "    iters += 1\n",
        "\n",
        "    model.learn(total_timesteps=timesteps, reset_num_timesteps=False, callback=eval_callback)\n",
        "    # model.save(f\"{models_dir.format(model_alg)}/{timesteps*iters}\")\n",
        "\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
