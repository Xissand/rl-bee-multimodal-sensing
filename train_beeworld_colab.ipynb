{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train BeeWorld with TD3 model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium\n",
    "!pip install stable_baselines3\n",
    "!git clone https://github.com/alTeska/rl-bee-multimodal-sensing.git\n",
    "!mv rl-bee-multimodal-sensing/bee.py ./"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import init_gym, init_model, setup_logging\n",
    "from utils import create_directory, set_device\n",
    "\n",
    "DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/content/drive/model-blablabla/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_name = \"BeeWorld\"\n",
    "base_path = \"drive/MyDrive/neuromatch/\"\n",
    "model_algo = \"TD3\"\n",
    "timesteps = 10000\n",
    "iters_max = 10\n",
    "learning_rate = 0.01\n",
    "policy_kwargs = {\"net_arch\": [100, 100], \"activation_fn\": nn.ReLU}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = base_path + \"models/\"\n",
    "logs_path = base_path + \"logs/\"\n",
    "replay_buffer_path = base_path + \"replay_buffer/\"\n",
    "best_model_save_path = models_path + \"{}\".format(model_algo)\n",
    "\n",
    "create_directory(models_path)\n",
    "create_directory(logs_path)\n",
    "create_directory(replay_buffer_path)\n",
    "create_directory(best_model_save_path)\n",
    "\n",
    "env = init_gym(gym_name, logs_path)\n",
    "callback, logger = setup_logging(env, logs_path, best_model_save_path)\n",
    "model = init_model(env, policy_kwargs, learning_rate, logger=logger)\n",
    "\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop (+ save model at each iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 0\n",
    "\n",
    "while iters < iters_max:\n",
    "    iters += 1\n",
    "\n",
    "    model_name = model_algo + \"_\" + str(timesteps * iters)\n",
    "    model_path = models_path + model_algo + \"/\" + model_name\n",
    "    replay_buffer_path = replay_buffer_path + model_algo + \"/\" + model_name\n",
    "\n",
    "    cur_model_zip_path = model_path + \".zip\"\n",
    "\n",
    "    # if we already have saved the model learning at this stage, load that model\n",
    "    # TODO: it is a bit akward, cause we just retrained the model and then check if exists and pick the old model?\n",
    "    if os.path.exists(cur_model_zip_path):\n",
    "        print(\"Loading this model:\", cur_model_zip_path)\n",
    "        model = TD3.load(cur_model_zip_path)\n",
    "        model.set_env(\n",
    "            DummyVecEnv([lambda: gym.make(\"BeeWorld\", render_mode=\"rgb_array\")])\n",
    "        )\n",
    "        model.load_replay_buffer(replay_buffer_path)\n",
    "\n",
    "    # train the model if no model saved at this stage yet\n",
    "    else:\n",
    "        model.learn(\n",
    "            total_timesteps=timesteps,\n",
    "            reset_num_timesteps=False,\n",
    "            callback=callback,\n",
    "        )\n",
    "        model.save(model_path)\n",
    "        model.save_replay_buffer(replay_buffer_path)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'drive/MyDrive/2023Neuromatch/logs/TD3LR_0p01_100_100_20230719_114053/' --port=80"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
